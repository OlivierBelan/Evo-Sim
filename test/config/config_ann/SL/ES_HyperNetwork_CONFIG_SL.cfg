[Runner_Info]
runner_type = Supervised

# used in Reinforcement and Supervised
batch_population=100

# used in Supervised only -> is the number of features from the data set used per run
batch_features=569

# has to smaller than batch_features other wise it will be set to batch_features
# is the number of features used during the run
batch_running=285


[NEURO_EVOLUTION]
verbose = True
# maximize, minimize or closest_to_zero
optimization_type = maximize
algo_name = HYPERNEAT

[Record]
criteria=fitness
sorted_by=fitness


[Genome_NN]
inputs = 13
hiddens = H1:64
# hiddens = H1:64, H2:64
# hiddens = H1:10, H2:10, H3:10
outputs = 3
inputs_multiplicator = 1
hiddens_multiplicator = 1
outputs_multiplicator = 1

is_self_neuron_connection = True

# forward = I->(H1_relu_norm), H1->(H2_relu_norm), H2->O_tanh
# forward = I->(H1_relu_norm), H1->(H2_relu_norm), H2->(H3_relu_norm), H3->O_tanh
forward = I->(H1_relu,O_tanh), H1->(H1_relu,O_tanh), O->(H1_relu, O_tanh)
# forward = (H1, H2_prev)_tanh_norm->(H1_norm_sigmoid, H2_relu), (H1,H2)_norm_relu->O, O_tanh
# forward = (H1, H2_prev)_tanh_norm->H1, (H1,H2)_norm_relu->O, O_tanh

# architecture = I->H1, H1->H2, H2->O
# architecture = I->H1, H1->H2, H2->H3, H3->O
architecture = I->H1, I->O, H1->H1, H1->O, O->H1, O->O
# architecture = I->I, I->H1, I->O, H1->I, H1->H1, H1->O, O->I, O->H1, O->O
network_type = ANN


[ES_HyperNetwork]
pop_size = 128
verbose = False


[bias_neuron_parameter]
max = 0.0
min = 0.0

mu = 0.0
mu_max = 0.0
mu_min = 0.0

sigma = 0.0
sigma_max = 0.0
sigma_min = 0.0
sigma_decay = 0.999


[weight_synapse_parameter]
max = 10.0
min = -10.0

mu = 0.0
mu_max = 10.0
mu_min = 1.0

sigma = 2.5
sigma_max = 10.0
sigma_min = 0.0
sigma_decay = 0.999
