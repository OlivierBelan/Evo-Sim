[Runner_Info]
runner_type = Supervised

# used in Reinforcement and Supervised
batch_population=100

# used in Supervised only -> is the number of features from the data set used per run
batch_features=569

# has to smaller than batch_features other wise it will be set to batch_features
# is the number of features used during the run
batch_running=285


[NEURO_EVOLUTION]
verbose = True
# maximize, minimize or closest_to_zero
optimization_type = maximize
algo_name = OpenES-evosax

[Record]
criteria=fitness
sorted_by=fitness

[Genome_NN]
inputs = 13
hiddens = H1:32, H2:32
outputs = 3
inputs_multiplicator = 1
hiddens_multiplicator = 1
outputs_multiplicator = 1

is_self_neuron_connection = True

forward = I->(H1_relu_norm), H1->(H2_relu_norm), H2->O_tanh
# forward = I->(H1_relu_norm), H1->(H2_relu_norm), H2->(H3_relu_norm), H3->O_tanh
# forward = I->(H1_relu,O_tanh), H1->(H1_relu,O_tanh), O->(H1_relu, O_tanh)
# forward = (H1, H2_prev)_tanh_norm->(H1_norm_sigmoid, H2_relu), (H1,H2)_norm_relu->O, O_tanh
# forward = (H1, H2_prev)_tanh_norm->H1, (H1,H2)_norm_relu->O, O_tanh

architecture = I->H1, H1->H2, H2->O
# architecture = I->H1, H1->H2, H2->H3, H3->O
# architecture = I->H1, I->O, H1->H1, H1->O, O->H1, O->O
# architecture = I->I, I->H1, I->O, H1->I, H1->H1, H1->O, O->I, O->H1, O->O
network_type = ANN


[OpenES-evosax]
pop_size = 300
verbose = False

opt_name = adam
antithetic_sampling = True

learning_rate = 0.05
learning_rate_decay = 1.0
learning_rate_limit = 0.001

sigma_init = 0.03
sigma_decay = 1.0
sigma_limit = 0.01

mean_decay = 0.0


[weight_synapse_parameter]
max = 0.0
min = 0.0

mu = 0.0
mu_max = 0.0
mu_min = 0.0

sigma = 0.0
sigma_max = 0.0
sigma_min = 0.0
sigma_decay = 1.0

# [bias_neuron_parameter]
# max = 0.0
# min = 0.0

# mu = 0.0
# mu_max = 0.0
# mu_min = 0.0

# sigma = 0.0
# sigma_max = 0.0
# sigma_min = 0.0
# sigma_decay = 1.0
